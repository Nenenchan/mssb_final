{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9e0265f-12e3-43e9-adfd-b29337178b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from scipy import sparse\n",
    "\n",
    "# sklearn 相关\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# PyTorch 相关\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== 1. 读取并过滤数据 ====\n",
    "data_dir     = \"./data\"\n",
    "module       = \"FFF\"\n",
    "presentation = \"2013J\"\n",
    "\n",
    "# 1.1 读取并筛选 assessments\n",
    "assessments    = pd.read_csv(os.path.join(data_dir, \"assessments.csv\"))\n",
    "assessments    = assessments[\n",
    "    (assessments.code_module == module) &\n",
    "    (assessments.code_presentation == presentation)\n",
    "]\n",
    "# 1.2 vle 元数据不需要过滤\n",
    "vle_meta       = pd.read_csv(os.path.join(data_dir, \"vle.csv\"))\n",
    "\n",
    "# 1.3 studentVle\n",
    "student_vle    = pd.read_csv(os.path.join(data_dir, \"studentVle.csv\"))\n",
    "student_vle    = student_vle[\n",
    "    (student_vle.code_module == module) &\n",
    "    (student_vle.code_presentation == presentation)\n",
    "]\n",
    "\n",
    "# 1.4 studentAssessment （待与 assessments 合并后筛选）\n",
    "student_assess = pd.read_csv(os.path.join(data_dir, \"studentAssessment.csv\"))\n",
    "\n",
    "# 1.5 studentInfo\n",
    "student_info   = pd.read_csv(os.path.join(data_dir, \"studentInfo.csv\"))\n",
    "student_info   = student_info[\n",
    "    (student_info.code_module == module) &\n",
    "    (student_info.code_presentation == presentation)\n",
    "]\n",
    "\n",
    "# 1.6 registration\n",
    "registration   = pd.read_csv(os.path.join(data_dir, \"studentRegistration.csv\"))\n",
    "registration   = registration[\n",
    "    (registration.code_module == module) &\n",
    "    (registration.code_presentation == presentation)\n",
    "]\n",
    "\n",
    "# ==== 2. 特征工程 & 多表合并 ====\n",
    "# 2.1 VLE 行为（前4周）\n",
    "sv = student_vle.merge(\n",
    "    vle_meta[['id_site','activity_type']],\n",
    "    on='id_site', how='left'\n",
    ")\n",
    "sv = sv[sv['date'] <= 28]\n",
    "vle_agg = sv.groupby(['id_student','activity_type'])['sum_click'] \\\n",
    "            .sum().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# 2.2 评估表现（前4周）\n",
    "sa = student_assess.merge(\n",
    "    assessments[['id_assessment','date','assessment_type']],\n",
    "    on='id_assessment', how='inner'\n",
    ")\n",
    "sa = sa[sa['date'] <= 28]\n",
    "sa_agg = sa.groupby(['id_student','assessment_type']) \\\n",
    "           .agg(score_mean=('score','mean'),\n",
    "                attempts=('id_assessment','count')) \\\n",
    "           .unstack(fill_value=0)\n",
    "sa_agg.columns = ['_'.join(col) for col in sa_agg.columns]\n",
    "sa_agg = sa_agg.reset_index()\n",
    "\n",
    "# 2.3 注册信息\n",
    "reg = registration.copy()\n",
    "reg['has_withdrawn'] = reg['date_unregistration'].notna().astype(int)\n",
    "reg = reg[['id_student','has_withdrawn']]\n",
    "\n",
    "# 2.4 人口学 & 标签\n",
    "info = student_info.copy()\n",
    "info['label'] = info['final_result'].isin(['Fail','Withdrawn']).astype(int)\n",
    "info = info[[\n",
    "    'id_student','gender','region','highest_education',\n",
    "    'imd_band','age_band','num_of_prev_attempts',\n",
    "    'studied_credits','disability','label'\n",
    "]]\n",
    "\n",
    "# 2.5 合并所有\n",
    "dfs = [vle_agg, sa_agg, reg, info]\n",
    "df = reduce(lambda L,R: pd.merge(L, R, on='id_student', how='outer'), dfs)\n",
    "\n",
    "# 填充缺失\n",
    "num_cols = df.select_dtypes(include=['int','float']).columns\n",
    "cat_cols = ['gender','region','highest_education','imd_band',\n",
    "            'age_band','disability']\n",
    "df[num_cols] = df[num_cols].fillna(0)\n",
    "df[cat_cols] = df[cat_cols].fillna('missing')\n",
    "\n",
    "# ==== 3. X, y 准备 ====\n",
    "feature_cols = [c for c in df.columns if c not in ['id_student','label']]\n",
    "X = df[feature_cols]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62b77365-3747-47db-bd67-6777d6100a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 逻辑回归 评估 (FFF-2013J) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7628    0.9088    0.8294       329\n",
      "           1     0.8976    0.7388    0.8105       356\n",
      "\n",
      "    accuracy                         0.8204       685\n",
      "   macro avg     0.8302    0.8238    0.8199       685\n",
      "weighted avg     0.8328    0.8204    0.8196       685\n",
      "\n",
      "ROC-AUC: 0.9014463303848912\n",
      "\n",
      "逻辑回归 Top 10 特征 (coef)：\n",
      "                                         feature      coef\n",
      "0                                  has_withdrawn  3.099431\n",
      "1                                 score_mean_TMA -1.282397\n",
      "2  highest_education_Post Graduate Qualification  0.889866\n",
      "3                                  age_band_55<=  0.693176\n",
      "4                                 imd_band_10-20  0.614567\n",
      "5        highest_education_A Level or Equivalent -0.590165\n",
      "6              highest_education_No Formal quals -0.569961\n",
      "7                               imd_band_missing -0.547830\n",
      "8                                 imd_band_0-10%  0.499858\n",
      "9                                        subpage  0.444917\n"
     ]
    }
   ],
   "source": [
    "# ==== 4. 逻辑回归 Pipeline ====\n",
    "num_feats = X_train.select_dtypes(include='number').columns.tolist()\n",
    "cat_feats = [c for c in feature_cols if c in cat_cols]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_feats)\n",
    "])\n",
    "pipe_lr = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('clf', LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42))\n",
    "])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr  = pipe_lr.predict(X_test)\n",
    "y_proba_lr = pipe_lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== 逻辑回归 评估 (FFF-2013J) ===\")\n",
    "print(classification_report(y_test, y_pred_lr, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_lr))\n",
    "\n",
    "# 特征重要性（系数）\n",
    "ohe = pipe_lr.named_steps['pre'].named_transformers_['cat']\n",
    "ohe_names = ohe.get_feature_names_out(cat_feats)\n",
    "all_feats = np.concatenate([num_feats, ohe_names])\n",
    "coefs     = pipe_lr.named_steps['clf'].coef_.ravel()\n",
    "imp_lr = pd.DataFrame({\n",
    "    'feature': all_feats,\n",
    "    'coef': coefs,\n",
    "    'abs_coef': np.abs(coefs)\n",
    "}).sort_values('abs_coef', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n逻辑回归 Top 10 特征 (coef)：\")\n",
    "print(imp_lr.head(10)[['feature','coef']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996f7b14-41bd-4309-887a-74518075c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.5822\n",
      "Epoch 2/30, Loss: 0.4157\n",
      "Epoch 3/30, Loss: 0.3456\n",
      "Epoch 4/30, Loss: 0.3243\n",
      "Epoch 5/30, Loss: 0.3187\n",
      "Epoch 6/30, Loss: 0.3098\n",
      "Epoch 7/30, Loss: 0.3081\n",
      "Epoch 8/30, Loss: 0.2923\n",
      "Epoch 9/30, Loss: 0.2885\n",
      "Epoch 10/30, Loss: 0.2798\n",
      "Epoch 11/30, Loss: 0.2783\n",
      "Epoch 12/30, Loss: 0.2739\n",
      "Epoch 13/30, Loss: 0.2721\n",
      "Epoch 14/30, Loss: 0.2581\n",
      "Epoch 15/30, Loss: 0.2467\n",
      "Epoch 16/30, Loss: 0.2513\n",
      "Epoch 17/30, Loss: 0.2370\n",
      "Epoch 18/30, Loss: 0.2288\n",
      "Epoch 19/30, Loss: 0.2297\n",
      "Epoch 20/30, Loss: 0.2212\n",
      "Epoch 21/30, Loss: 0.2183\n",
      "Epoch 22/30, Loss: 0.2157\n",
      "Epoch 23/30, Loss: 0.2002\n",
      "Epoch 24/30, Loss: 0.1930\n",
      "Epoch 25/30, Loss: 0.1872\n",
      "Epoch 26/30, Loss: 0.1843\n",
      "Epoch 27/30, Loss: 0.1824\n",
      "Epoch 28/30, Loss: 0.1792\n",
      "Epoch 29/30, Loss: 0.1725\n",
      "Epoch 30/30, Loss: 0.1707\n",
      "\n",
      "=== MLP 评估 (FFF-2013J) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7768    0.8359    0.8053       329\n",
      "           1     0.8369    0.7781    0.8064       356\n",
      "\n",
      "    accuracy                         0.8058       685\n",
      "   macro avg     0.8068    0.8070    0.8058       685\n",
      "weighted avg     0.8080    0.8058    0.8059       685\n",
      "\n",
      "ROC-AUC: 0.8958710426556469\n",
      "\n",
      "MLP Top 10 特征 (permutation importance):\n",
      "                feature  importance\n",
      "0         has_withdrawn    0.218733\n",
      "1        score_mean_TMA    0.043573\n",
      "2                ouwiki    0.015187\n",
      "3                  quiz    0.009029\n",
      "4  num_of_prev_attempts    0.008728\n",
      "5     highest_education    0.007634\n",
      "6               forumng    0.007520\n",
      "7              homepage    0.007501\n",
      "8          attempts_TMA    0.006487\n",
      "9                   url    0.006120\n"
     ]
    }
   ],
   "source": [
    "# ==== 5. PyTorch MLP ====\n",
    "def to_numpy(df_):\n",
    "    arr = pre.transform(df_)\n",
    "    if sparse.issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "Xtr_np = to_numpy(X_train)\n",
    "Xte_np = to_numpy(X_test)\n",
    "ytr_np = y_train.values.astype(np.int64)\n",
    "yte_np = y_test.values.astype(np.int64)\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(Xtr_np), torch.from_numpy(ytr_np))\n",
    "test_ds  = TensorDataset(torch.from_numpy(Xte_np), torch.from_numpy(yte_np))\n",
    "train_ld = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_ld  = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim,128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128,64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64,2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(Xtr_np.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1,31):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_ld:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    print(f\"Epoch {epoch}/30, Loss: {total_loss/len(train_ds):.4f}\")\n",
    "\n",
    "# 5.2 MLP 评估\n",
    "model.eval()\n",
    "preds, probs, trues = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_ld:\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb)\n",
    "        p = torch.softmax(out, dim=1)[:,1].cpu().numpy()\n",
    "        y = out.argmax(dim=1).cpu().numpy()\n",
    "        probs.extend(p); preds.extend(y); trues.extend(yb.numpy())\n",
    "\n",
    "print(\"\\n=== MLP 评估 (FFF-2013J) ===\")\n",
    "print(classification_report(trues, preds, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(trues, probs))\n",
    "\n",
    "# ==== 6. MLP 置换重要性 ====\n",
    "class MLPWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, pre, device):\n",
    "        self.model = model\n",
    "        self.pre = pre\n",
    "        self.device = device\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        arr = self.pre.transform(X)\n",
    "        if sparse.issparse(arr): arr = arr.toarray()\n",
    "        t = torch.from_numpy(arr.astype(np.float32)).to(self.device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.model(t)\n",
    "            probs = torch.softmax(out, dim=1)[:,1].cpu().numpy()\n",
    "        return (probs >= 0.5).astype(int)\n",
    "    def predict_proba(self, X):\n",
    "        arr = self.pre.transform(X)\n",
    "        if sparse.issparse(arr): arr = arr.toarray()\n",
    "        t = torch.from_numpy(arr.astype(np.float32)).to(self.device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.model(t)\n",
    "            probs = torch.softmax(out, dim=1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "mlp_wrap = MLPWrapper(model, pre, device)\n",
    "res = permutation_importance(\n",
    "    estimator=mlp_wrap,\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    scoring=lambda est, X, y: roc_auc_score(y, est.predict_proba(X)[:,1]),\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "imp_mlp = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': res.importances_mean\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nMLP Top 10 特征 (permutation importance):\")\n",
    "print(imp_mlp.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890c34b-1583-47fd-93e4-5ccb67aa4ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_py310",
   "language": "python",
   "name": "ml_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
